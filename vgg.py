# -*- coding: utf-8 -*-
"""vgg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1soo3bgGFOffTW0idQ4rd-lpe6D2KPYUC
"""

!pip install kaggle
from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
  
# Then move kaggle.json into the folder where the API expects to find it.
!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d moltean/fruits

!unzip ./fruits.zip

import tensorflow as tf
import keras
from glob import glob
import matplotlib.pyplot as plt

traning_file="./fruits-360-original-size/fruits-360-original-size/Training"
test_file="./fruits-360-original-size/fruits-360-original-size/Test"
validation_file="./fruits-360-original-size/fruits-360-original-size/Validation"

traning_file_image=glob(traning_file+"/*/*.jp*g")
test_file_image=glob(test_file+"/*/*.jp*g")
validation_file_image=glob(validation_file+"/*/*.jp*g")

gen=keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True,vertical_flip=True
                                             ,shear_range=0.1,width_shift_range=1.0,
                                             height_shift_range=0.1,
                                             zoom_range=0.1,
                                             preprocessing_function=keras.applications.vgg16.preprocess_input)

training_data=gen.flow_from_directory(traning_file,target_size=(100,100))

test_data=gen.flow_from_directory(test_file,target_size=(100,100))

validation_data=gen.flow_from_directory(validation_file,target_size=(100,100))

vgg=keras.applications.vgg16.VGG16(include_top=False,input_shape=(100,100,3))

for layer in vgg.layers:
  layer.trainable=False

x=keras.layers.Flatten()(vgg.output)
x=keras.layers.Dense(24,activation="softmax")(x)

model=keras.Model(vgg.input,x)

model.compile(loss=keras.losses.categorical_crossentropy,metrics=["accuracy"])

history=model.fit(training_data,batch_size=32,epochs=10,
          steps_per_epoch=len(traning_file_image)//32,
          validation_data=validation_data,
          validation_steps=len(validation_file_image)//32
          )

plt.plot(history.history["accuracy"],label="accuracy")
plt.plot(history.history["val_accuracy"],label="val_accuracy")
plt.legend()
plt.show()

plt.plot(history.history["loss"],label="loss")
plt.plot(history.history["val_loss"],label="val_loss")
plt.legend()
plt.show()

model.summary()

